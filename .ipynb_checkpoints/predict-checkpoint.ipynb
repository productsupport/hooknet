{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib as mpl\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from utils.dataGenerator import DataGenerator\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tf version: \", tf.__version__)\n",
    "print(\"keras version: \", tf.keras.__version__)\n",
    "print(\"\")\n",
    "\n",
    "# GPU availability\n",
    "tf.test.gpu_device_name()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data folders\n",
    "patches_folder = r\"D:\\annotated_slides\\separate_patches_and_labels_hooknet_exp_1\"\n",
    "svsfolder = r\"D:\\annotated_slides\\Slides\"\n",
    "\n",
    "slide_patches = glob.glob(os.path.join(patches_folder,'*.h5'))\n",
    "print(\"number of slide patches: \", len(slide_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load csv file\n",
    "# df = pd.read_csv(os.path.join(svsfolder, \"csv_file.csv\"))\n",
    "\n",
    "# slide_ids = list(df['slide_id'].values)\n",
    "# train_ids, val_test_ids = train_test_split(slide_ids, test_size=0.30, random_state=42)\n",
    "# validation_ids, test_ids = train_test_split(val_test_ids, test_size=0.35, random_state=42)\n",
    "\n",
    "# print(\"train: {:d}, validation: {:d}, test: {:d}\".format(len(train_ids), len(validation_ids), len(test_ids)))  \n",
    "\n",
    "# train_patches = []\n",
    "# validation_patches = []\n",
    "# test_patches = []\n",
    "# for patch_path in slide_patches:\n",
    "#     patch_name = patch_path.split(\"\\\\\")[-1]\n",
    "    \n",
    "#     for tran_id in train_ids:\n",
    "#         if tran_id in patch_name:\n",
    "#             train_patches.append(patch_name)\n",
    "#             break\n",
    "    \n",
    "#     for val_id in validation_ids:\n",
    "#         if val_id in patch_name:\n",
    "#             validation_patches.append(patch_name)\n",
    "#             break\n",
    "            \n",
    "#     for test_id in test_ids:\n",
    "#         if test_id in patch_name:\n",
    "#             test_patches.append(patch_name)\n",
    "#             break\n",
    "            \n",
    "# # # print([x for x in train_patches if x in validation_pathes])\n",
    "# print(\"train patches: {:d}, validation patches: {:d}, test patches: {:d}\".format(\n",
    "#     len(train_patches), len(validation_patches), len(test_patches)))  \n",
    "\n",
    "# partition = {'train': train_patches,\n",
    "#              'validation': validation_patches,\n",
    "#              'test': test_patches}\n",
    "\n",
    "classmeta_test = pd.read_csv(os.path.join(patches_folder, \"classmeta_test.csv\"))\n",
    "classmeta_validation = pd.read_csv(os.path.join(patches_folder, \"classmeta_validation.csv\"))\n",
    "classmeta_train = pd.read_csv(os.path.join(patches_folder, \"classmeta_train.csv\"))\n",
    "\n",
    "print(\"test patches: {:d}\".format(len(classmeta_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "main_folder = r\"D:\\annotated_slides\"\n",
    "modeldir = os.path.join(main_folder, 'models')\n",
    "modelfile = 'model_hooknet_exp_1.h5'\n",
    "hooknet = load_model(os.path.join(modeldir, modelfile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'dim': (256, 256),\n",
    "#           'batch_size': 2, \n",
    "#           'n_classes': 11,\n",
    "#           'n_channels': 3,\n",
    "#           'shuffle': True,\n",
    "#           'data_folder': r\"D:\\annotated_slides\\separate_patches_and_labels\"}\n",
    "\n",
    "# # without augmentation\n",
    "# test_generator = DataGenerator(partition['test'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = ['Mastopatic', 'CIS', 'Necrosis', 'NormalEpithelial', 'IDC', 'Stroma', 'Lymfocyten',\n",
    "              'Adipose', 'RedBlood', 'ILC']\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "if classnames is not None:\n",
    "    le.fit(classnames)\n",
    "    print('classes: ', list(le.classes_))\n",
    "    new_class_names = ['unknown'] + list(le.classes_)\n",
    "#     new_class_names = list(le.classes_)\n",
    "\n",
    "\n",
    "print(\"new class names: \", new_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom color map\n",
    "\n",
    "N = 11  # Number of labels\n",
    "\n",
    "# colors for segmented classes\n",
    "colorB = [255, 128, 232, 70, 156, 153, 153,  30,   0,  35, 152]\n",
    "colorG = [255,  64,  35, 70, 102, 153, 153, 170, 220, 142, 251]\n",
    "colorR = [255, 128, 244, 70, 102, 190, 153, 250, 220, 107, 152]\n",
    "colorA = [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255]\n",
    "CLASS_COLOR = list()\n",
    "for i in range(0, len(colorB)):\n",
    "    CLASS_COLOR.append([colorR[i], colorG[i], colorB[i], colorA[i]])\n",
    "COLORS = np.array(CLASS_COLOR, dtype=\"float32\")\n",
    "COLORS = COLORS/255\n",
    "\n",
    "cmap = colors.ListedColormap(COLORS)\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0, N, N + 1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N, clip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classmeta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsz = 256\n",
    "\n",
    "for patch_name in classmeta_test['patch_name'].values[3000:3001]:\n",
    "# for patch_name in classmeta_validation['patch_name'].values[6:7]:\n",
    "# for patch_name in classmeta_train['patch_name'].values[100:101]:\n",
    "    print(\"patch name: \", patch_name)\n",
    "    with h5py.File(os.path.join(patches_folder, patch_name), 'r') as f:\n",
    "        patch_t = f['patches_20x']['patch'][:]\n",
    "        patch_c = f['patches_5x']['patch'][:]\n",
    "        seg_t = f['patches_20x']['segmentation'][:]\n",
    "        seg_c = f['patches_5x']['segmentation'][:]\n",
    "\n",
    "        patch_t = patch_t.astype('float') / 255\n",
    "        patch_c = patch_c.astype('float') / 255\n",
    "                \n",
    "        seg_ids_t, seg_counts_t = np.unique(seg_t, return_counts=True)\n",
    "        print(\"original segmentation stats (target):\", seg_ids_t, seg_counts_t)\n",
    "\n",
    "        seg_ids_c, seg_counts_c = np.unique(seg_c, return_counts=True)\n",
    "        print(\"original segmentation stats (context):\", seg_ids_c, seg_counts_c)\n",
    "\n",
    "        \n",
    "        seg_class_names = [new_class_names[idx] for idx in seg_ids_t]\n",
    "        seg_data = tuple(zip(list(seg_ids_t), seg_class_names, list(seg_counts_t)))\n",
    "        df_seg = pd.DataFrame(seg_data, columns=['class_id', 'class_name', 'class_count'])\n",
    "        \n",
    "        \n",
    "        patch_c = np.reshape(patch_c, (1, tsz, tsz, -1))\n",
    "        patch_t = np.reshape(patch_t, (1, tsz, tsz, -1))\n",
    "\n",
    "            \n",
    "        pred_c, pred_t = unet_classifier.predict([patch_c, patch_t])\n",
    "        \n",
    "        pred_c = np.reshape(pred_c, (1, tsz, tsz, -1))\n",
    "        pred_c = np.argmax(pred_c, axis=-1)\n",
    "        pred_c = np.reshape(pred_c, (tsz, tsz))\n",
    "        print(\"predicted segmentation stats (context):\", np.unique(pred_c, return_counts=True))\n",
    "        \n",
    "        pred_t = np.reshape(pred_t, (1, tsz, tsz, -1))\n",
    "        pred_t = np.argmax(pred_t, axis=-1)\n",
    "        pred_t = np.reshape(pred_t, (tsz, tsz))\n",
    "        print(\"predicted segmentation stats (target):\", np.unique(pred_t, return_counts=True))\n",
    "        \n",
    "        pred_ids, pred_counts = np.unique(pred_t, return_counts=True)\n",
    "        pred_class_names = [new_class_names[idx] for idx in pred_ids]\n",
    "        pred_data = tuple(zip(list(pred_ids), pred_class_names, list(pred_counts)))\n",
    "        df_pred = pd.DataFrame(pred_data, columns=['class_id', 'class_name', 'class_count_pred'])\n",
    "        \n",
    "        df = df_seg.merge(df_pred, on=['class_id', 'class_name'], how='outer')\n",
    "        print(df)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    ax[0].imshow(np.reshape(patch_t, (tsz, tsz, -1)))\n",
    "    ax[0].set_title(\"patch\")\n",
    "    seg_image = ax[1].imshow(seg_t, cmap, norm=norm, interpolation='nearest')\n",
    "    ax[1].set_title(\"segmentation\")\n",
    "    pred_image = ax[2].imshow(pred_t, cmap, norm=norm, interpolation='nearest')\n",
    "    ax[2].set_title(\"predicted segmentation\")\n",
    "    \n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    cbar_ax = fig.add_axes([0.95, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(pred_image, spacing='proportional', ticks=bounds, cax=cbar_ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 11 # Number of labels\n",
    "\n",
    "# setup the plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "# define the data\n",
    "x = np.random.rand(1000)\n",
    "y = np.random.rand(1000)\n",
    "# tag = np.random.randint(0, N, N) # Tag each point with a corresponding label\n",
    "# print(tag)\n",
    "\n",
    "# define the colormap\n",
    "cmap = plt.cm.jet\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "print(cmap.N)\n",
    "\n",
    "# create the new map\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0, N, N + 1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "print(bounds)\n",
    "# print(norm)\n",
    "\n",
    "# setup the plot\n",
    "image = ax.imshow(pred, cmap='viridis', vmin=0, vmax=10, norm=norm, interpolation='nearest') # , cmap=cmap , norm=norm)\n",
    "\n",
    "    \n",
    "# scat = ax.scatter(x,y,c=tag,s=np.random.randint(100,500,N),cmap=cmap,     norm=norm)\n",
    "# create the colorbar\n",
    "cb = plt.colorbar(image, spacing='proportional', ticks=bounds)\n",
    "cb.set_label('Custom cbar')\n",
    "ax.set_title('Discrete color mappings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
