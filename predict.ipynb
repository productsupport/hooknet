{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib as mpl\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from utils.dataGenerator import DataGenerator, DataGenerator_metaData\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tf version: \", tf.__version__)\n",
    "print(\"keras version: \", tf.keras.__version__)\n",
    "print(\"\")\n",
    "\n",
    "# GPU availability\n",
    "tf.test.gpu_device_name()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data folders\n",
    "patches_folder = r\"D:\\annotated_slides\\separate_patches_and_labels\"\n",
    "svsfolder = r\"D:\\annotated_slides\\Slides\"\n",
    "\n",
    "slide_patches = glob.glob(os.path.join(patches_folder,'*.h5'))\n",
    "print(\"number of slide patches: \", len(slide_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "\n",
    "# classmeta_test = pd.read_csv(os.path.join(patches_folder, \"classmeta_test.csv\"))\n",
    "classmeta_validation = pd.read_csv(os.path.join(patches_folder, \"classmeta_validation.csv\"))\n",
    "classmeta_train = pd.read_csv(os.path.join(patches_folder, \"classmeta_train.csv\"))\n",
    "\n",
    "# print(\"test patches: {:d}\".format(len(classmeta_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "main_folder = r\"D:\\annotated_slides\"\n",
    "modeldir = os.path.join(main_folder, 'models/hooknet/exp_2')\n",
    "modelfile = 'model_hooknet_exp_2.h5'\n",
    "hooknet = load_model(os.path.join(modeldir, modelfile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classnames = ['Mastopatic', 'CIS', 'Necrosis', 'NormalEpithelial', 'IDC', 'Stroma', 'Lymfocyten',\n",
    "#               'Adipose', 'RedBlood', 'ILC']\n",
    "classnames = ['InvTumour', 'Stroma', 'Adipose', 'Other']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "if classnames is not None:\n",
    "    le.fit(classnames)\n",
    "    print('classes: ', list(le.classes_))\n",
    "    new_class_names = ['unknown'] + list(le.classes_)\n",
    "#     new_class_names = list(le.classes_)\n",
    "\n",
    "\n",
    "print(\"new class names: \", new_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom color map\n",
    "\n",
    "N = 5  # Number of labels\n",
    "\n",
    "# colors for segmented classes\n",
    "colorB = [255, 128, 232, 70, 156, 153, 153,  30,   0,  35, 152]\n",
    "colorG = [255,  64,  35, 70, 102, 153, 153, 170, 220, 142, 251]\n",
    "colorR = [255, 128, 244, 70, 102, 190, 153, 250, 220, 107, 152]\n",
    "colorA = [255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255]\n",
    "CLASS_COLOR = list()\n",
    "for i in range(0, len(colorB)):\n",
    "    CLASS_COLOR.append([colorR[i], colorG[i], colorB[i], colorA[i]])\n",
    "COLORS = np.array(CLASS_COLOR, dtype=\"float32\")\n",
    "COLORS = COLORS/255\n",
    "\n",
    "cmap = colors.ListedColormap(COLORS)\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0, N, N + 1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N, clip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (256, 256),\n",
    "          'batch_size': 14, \n",
    "          'n_classes': 5,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "          'mode': 'test',\n",
    "          'data_folder': r\"D:\\annotated_slides\\separate_patches_and_labels\"}\n",
    "\n",
    "# Generator\n",
    "# test_generator =  DataGenerator_metaData(classmeta_test, **params)\n",
    "validation_generator = DataGenerator_metaData(classmeta_validation, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data generator\n",
    "max_iter = 1  # maximum number of iterations, in each iteration one batch is generated; the proper value depends on batch size and size of whole data\n",
    "i = 0\n",
    "for (patch_c, patch_t), (seg_c, seg_t) in validation_generator:  # test_generator\n",
    "    i += 1\n",
    "    if i == max_iter:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "ax[0][0].imshow(patch_c[i])\n",
    "ax[0][1].imshow(patch_t[i])\n",
    "ax[1][0].imshow(seg_c[i])\n",
    "ax[1][1].imshow(seg_t[i])\n",
    "\n",
    "print(\"seg_c: \", np.unique(seg_c[i], return_counts=True))\n",
    "print(\"seg_t: \", np.unique(seg_t[i], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use testGenerator\n",
    "tsz = 256\n",
    "max_iter = 2 # int(np.floor(len(classmeta_test) / params['batch_size']))  \n",
    "i = 0\n",
    "for (X_c, X_t), (Y_c, Y_t) in validation_generator:\n",
    "    i += 1\n",
    "\n",
    "        \n",
    "    YP_c, YP_t = hooknet.predict([X_c, X_t])\n",
    "    YP_t = np.reshape(YP_t, (len(YP_t), tsz, tsz, -1))\n",
    "    YP_t = np.argmax(YP_t, axis=-1)\n",
    "    YP_c = np.reshape(YP_c, (len(YP_c), tsz, tsz, -1))\n",
    "    YP_c = np.argmax(YP_c, axis=-1)\n",
    "    \n",
    "    for j in range(params['batch_size']):\n",
    "        x_c = X_c[j]\n",
    "        x_t = X_t[j]\n",
    "        y_c = Y_c[j]\n",
    "        y_t = Y_t[j]\n",
    "        \n",
    "        yp_c = YP_c[j]\n",
    "        yp_t = YP_t[j]\n",
    "        \n",
    "        y_t_ids, y_t_counts = np.unique(y_t, return_counts=True)\n",
    "#         print(\"original segmentation stats (target):\", y_t_ids, y_t_counts)\n",
    "    \n",
    "        y_c_ids, y_c_counts = np.unique(y_c, return_counts=True)\n",
    "#         print(\"original segmentation stats (context):\", y_c_ids, y_c_counts)\n",
    "        \n",
    "        y_t_class_names = [new_class_names[int(idx)] for idx in y_t_ids]\n",
    "        y_t_data = tuple(zip(list(y_t_ids), y_t_class_names, list(y_t_counts)))\n",
    "        df_y_t = pd.DataFrame(y_t_data, columns=['class_id', 'class_name', 'y_class_count'])\n",
    "        \n",
    "        yp_t_ids, yp_t_counts = np.unique(yp_t, return_counts=True)\n",
    "#         print(\"predicted segmentation stats (target):\", yp_t_ids, yp_t_counts)\n",
    "    \n",
    "        yp_c_ids, yp_c_counts = np.unique(yp_c, return_counts=True)\n",
    "#         print(\"predicted segmentation stats (context):\", yp_c_ids, yp_c_counts)\n",
    "        \n",
    "        yp_t_class_names = [new_class_names[int(idx)] for idx in yp_t_ids]\n",
    "        yp_t_data = tuple(zip(list(yp_t_ids), yp_t_class_names, list(yp_t_counts)))\n",
    "        df_yp_t = pd.DataFrame(yp_t_data, columns=['class_id', 'class_name', 'yp_class_count'])\n",
    "        \n",
    "        df = df_y_t.merge(df_yp_t, on=['class_id', 'class_name'], how='outer')\n",
    "        print(df)\n",
    "        \n",
    "        fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        ax[0][0].imshow(x_t)\n",
    "        ax[0][0].set_title(\"target patch\")\n",
    "        seg_image = ax[0][1].imshow(y_t, cmap, norm=norm, interpolation='nearest')\n",
    "        ax[0][1].set_title(\"target segmentation\")\n",
    "        pred_image = ax[0][2].imshow(yp_t, cmap, norm=norm, interpolation='nearest')\n",
    "        ax[0][2].set_title(\"target predicted segmentation\")\n",
    "\n",
    "        ax[1][0].imshow(x_c)\n",
    "        ax[1][0].set_title(\"context patch\")\n",
    "        seg_image = ax[1][1].imshow(y_c, cmap, norm=norm, interpolation='nearest')\n",
    "        ax[1][1].set_title(\"context segmentation\")\n",
    "        pred_image = ax[1][2].imshow(yp_c, cmap, norm=norm, interpolation='nearest')\n",
    "        ax[1][2].set_title(\"context predicted segmentation\")\n",
    "\n",
    "        fig.subplots_adjust(right=0.9)\n",
    "        cbar_ax = fig.add_axes([0.95, 0.15, 0.05, 0.7])\n",
    "        fig.colorbar(pred_image, spacing='proportional', ticks=bounds, cax=cbar_ax)\n",
    "        plt.show()\n",
    "    \n",
    "    if i == max_iter:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YP_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsz = 256\n",
    "\n",
    "# for patch_name in classmeta_test['patch_name'].values[900:901]:\n",
    "# for patch_name in classmeta_validation['patch_name'].values[6:7]:\n",
    "# for patch_name in classmeta_train['patch_name'].values[100:101]:\n",
    "    print(\"patch name: \", patch_name)\n",
    "    with h5py.File(os.path.join(patches_folder, patch_name), 'r') as f:\n",
    "        patch_t = f['patches_20x']['patch'][:]\n",
    "        patch_c = f['patches_5x']['patch'][:]\n",
    "        seg_t = f['patches_20x']['segmentation'][:]\n",
    "        seg_c = f['patches_5x']['segmentation'][:]\n",
    "\n",
    "        patch_t = patch_t.astype('float') / 255\n",
    "        patch_c = patch_c.astype('float') / 255\n",
    "                \n",
    "        seg_ids_t, seg_counts_t = np.unique(seg_t, return_counts=True)\n",
    "        print(\"original segmentation stats (target):\", seg_ids_t, seg_counts_t)\n",
    "\n",
    "        \n",
    "        seg_class_names = [new_class_names[idx] for idx in seg_ids_t]\n",
    "        seg_data = tuple(zip(list(seg_ids_t), seg_class_names, list(seg_counts_t)))\n",
    "        df_seg = pd.DataFrame(seg_data, columns=['class_id', 'class_name', 'class_count'])\n",
    "        \n",
    "        \n",
    "        patch_c = np.reshape(patch_c, (1, tsz, tsz, -1))\n",
    "        patch_t = np.reshape(patch_t, (1, tsz, tsz, -1))\n",
    "\n",
    "            \n",
    "        pred_c, pred_t = hooknet.predict([patch_c, patch_t])\n",
    "        \n",
    "        pred_c = np.reshape(pred_c, (1, tsz, tsz, -1))\n",
    "        pred_c = np.argmax(pred_c, axis=-1)\n",
    "        pred_c = np.reshape(pred_c, (tsz, tsz))\n",
    "        print(\"predicted segmentation stats (context):\", np.unique(pred_c, return_counts=True))\n",
    "        \n",
    "        pred_t = np.reshape(pred_t, (1, tsz, tsz, -1))\n",
    "        pred_t = np.argmax(pred_t, axis=-1)\n",
    "        pred_t = np.reshape(pred_t, (tsz, tsz))\n",
    "        print(\"predicted segmentation stats (target):\", np.unique(pred_t, return_counts=True))\n",
    "        \n",
    "        pred_ids, pred_counts = np.unique(pred_t, return_counts=True)\n",
    "        pred_class_names = [new_class_names[idx] for idx in pred_ids]\n",
    "        pred_data = tuple(zip(list(pred_ids), pred_class_names, list(pred_counts)))\n",
    "        df_pred = pd.DataFrame(pred_data, columns=['class_id', 'class_name', 'class_count_pred'])\n",
    "        \n",
    "        df = df_seg.merge(df_pred, on=['class_id', 'class_name'], how='outer')\n",
    "        print(df)\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    ax[0][0].imshow(np.reshape(patch_t, (tsz, tsz, -1)))\n",
    "    ax[0][0].set_title(\"target patch\")\n",
    "    seg_image = ax[0][1].imshow(seg_t, cmap, norm=norm, interpolation='nearest')\n",
    "    ax[0][1].set_title(\"target segmentation\")\n",
    "    pred_image = ax[0][2].imshow(pred_t, cmap, norm=norm, interpolation='nearest')\n",
    "    ax[0][2].set_title(\"target predicted segmentation\")\n",
    "    \n",
    "    ax[1][0].imshow(np.reshape(patch_c, (tsz, tsz, -1)))\n",
    "    ax[1][0].set_title(\"context patch\")\n",
    "    seg_image = ax[1][1].imshow(seg_c, cmap, norm=norm, interpolation='nearest')\n",
    "    ax[1][1].set_title(\"context segmentation\")\n",
    "    pred_image = ax[1][2].imshow(pred_c, cmap, norm=norm, interpolation='nearest')\n",
    "    ax[1][2].set_title(\"context predicted segmentation\")\n",
    "    \n",
    "    fig.subplots_adjust(right=0.9)\n",
    "    cbar_ax = fig.add_axes([0.95, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(pred_image, spacing='proportional', ticks=bounds, cax=cbar_ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 11 # Number of labels\n",
    "\n",
    "# setup the plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "# define the data\n",
    "x = np.random.rand(1000)\n",
    "y = np.random.rand(1000)\n",
    "# tag = np.random.randint(0, N, N) # Tag each point with a corresponding label\n",
    "# print(tag)\n",
    "\n",
    "# define the colormap\n",
    "cmap = plt.cm.jet\n",
    "# extract all colors from the .jet map\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "print(cmap.N)\n",
    "\n",
    "# create the new map\n",
    "cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "\n",
    "# define the bins and normalize\n",
    "bounds = np.linspace(0, N, N + 1)\n",
    "norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "print(bounds)\n",
    "# print(norm)\n",
    "\n",
    "# setup the plot\n",
    "image = ax.imshow(pred, cmap='viridis', vmin=0, vmax=10, norm=norm, interpolation='nearest') # , cmap=cmap , norm=norm)\n",
    "\n",
    "    \n",
    "# scat = ax.scatter(x,y,c=tag,s=np.random.randint(100,500,N),cmap=cmap,     norm=norm)\n",
    "# create the colorbar\n",
    "cb = plt.colorbar(image, spacing='proportional', ticks=bounds)\n",
    "cb.set_label('Custom cbar')\n",
    "ax.set_title('Discrete color mappings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
